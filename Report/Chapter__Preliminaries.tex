
\chapter{Preliminaries}



\section{Modeling}

\subsection{Flux dynamics}
We utilize the discrete time dynamics of the stator and rotor fluxes $\b{\psi}_s$ and $\b{\psi}_r$ from \cite[\S4.2]{gey_book} in (4.33):
\begin{align*}
	\b{\psi}_s(k+1) &= \b{A}_{1,1}\b{\psi}_s(k) + \b{A}_{1,2}\b{\psi}_r(k) + \b{B}_1\b{u}(k), \\
	\b{\psi}_r(k+1) &= \b{A}_{2,1}\b{\psi}_s(k) + \b{A}_{2,2}\b{\psi}_r(k),
\end{align*}
where $\b{u}(k) \in \{-1,0,1\}^3$ is the normalized input.
These dynamics can be summarized to
\begin{equation*}
	\b{x}(k+1) = \b{Ax}(k) + \b{Bu}(k),
\end{equation*}
where
\begin{equation*}
	A = \left[\begin{array}{cc}
		\b{A}_{1,1} & \b{A}_{1,2} \\
		\b{A}_{2,1} & \b{A}_{2,2}
	\end{array}\right],\ \b{B} = \left[\begin{array}{c}
		\b{B}_1 \\
		\b{0}
	\end{array}\right].
\end{equation*}
Assume the state $x(k)$, all inputs $\b{u}(k),\ \b{u}(k+1),\ldots,\ \b{u}(k+l-1)$, and $l \geq 2$ are given. Then the values of the rotor and stator flux at time step $k+l$ can be computed as
\begin{align}\label{eq:0}
	\b{\psi}_s(k+l) &= \left[\b{A}_{1,1}\ \b{A}_{1,2}\right]\b{A}^{l-1}\b{x}(k) + \left[\b{A}_{1,1}\ \b{A}_{1,2}\right]\b{A}^{l-2}\b{Bu}(k) + \\
	&\ + \left[\b{A}_{1,1}\ \b{A}_{1,2}\right]\b{A}^{l-3}\b{Bu}(k+1) + \ldots + \left[\b{A}_{1,1}\ \b{A}_{1,2}\right]\b{Bu}(k+l-2) + \b{B}_1\b{u}(k+l-1) \nonumber
\end{align}
and
\begin{align} \label{eq:1}
	\b{\psi}_r(k+l) &= \left[\b{A}_{2,1}\ \b{A}_{2,2}\right]\b{A}^{l-1}\b{x}(k) + \left[\b{A}_{2,1}\ \b{A}_{2,2}\right]\b{A}^{l-2}\b{Bu}(k) + \\
	&\ + \left[\b{A}_{2,1}\ \b{A}_{2,2}\right]\b{A}^{l-3}\b{Bu}(k+1) + \ldots + \left[\b{A}_{2,1}\ \b{A}_{2,2}\right]\b{Bu}(k+l-2). \nonumber
\end{align}




\subsection{Torque and stator flux magnitude}

The stator flux magnitude is computed via the $\ell_2$-norm,
\begin{equation*}
	\Psi_s(k) = ||\b{\psi}_s(k)||_2.
\end{equation*}
The electric torque $T$ is defined as
\begin{equation*}
	T(k) = \frac{1}{\mathrm{pf}}\frac{X_m}{D}\b{\psi}_r\times\b{\psi}_s = \Tfac\b{\psi}_r\times\b{\psi}_s,
\end{equation*}
where $\mathrm{pf},\ X_m,$ and $D$ resemble machine parameters and are summarized under $\Tfac = \frac{1}{pf}\frac{X_m}{D}$. The operator $\times$ is the cross-product and can be replaced by the matrix $\Xi$:
\begin{equation*}
	\b{\psi}_r\times\b{\psi}_s = \b{\psi}_r^\top\Xi\b{\psi}_s,\ \text{where } \Xi = \left[\begin{array}{cc}
		0 & 1 \\
		-1 & 0
	\end{array}\right].
\end{equation*}





\section{Conventional FCS-MPC for torque tracking}

\subsection{Problem formulation}
The FCS-MPC for torque tracking is realized as an optimization problem. This requires the definition of a cost function. We start by defining the cost for a 1-step controller, and choose a term similar to \cite[\S4.2]{gey_book}.
\begin{equation*}
	J(k) = \lambda_T ||T^*(k+1)-T(k+1)||_2^2 + (1-\lambda_T) || (\Psi_s^*(k+1))^2-(\Psi_s(k+1))^2||_2^2 + \lambda_u ||\Delta \b{u}(k)||_1,
\end{equation*}
where $T^*(k)$ and $\Psi_s^*(k)$ refer to the Torque- and stator flux magnitude references, respectively. Note, that the stator flux magnitude tracking term uses the squared quantities of the reference and the stator flux magnitude. This is required to later use semi-definite programming relaxations (Section \ref{sec:3}), and does not make a difference for the problem formulation. For the sake of simplicity, in subsequent sections, we will refer to this controller as FCS-MPC for torque tracking. Nevertheless, stator flux magnitude tracking is performed as well.

We want to extend the 1-step by a multi-step controller with a horizon of $N \in \mathbb{N}$. As a result we obtain the following cost function
\begin{align}\label{eq:2}
	J_N(U(k)) &= \sum_{l = k}^{k+N-1} \lambda_T ||T^*(l+1)-T(l+1)||_2^2 + (1-\lambda_T) ||(\Psi_s^*(l+1))^2-(\Psi_s(l+1))^2||_2^2 + \lambda_u ||\Delta \b{u}(l)||_1 \nonumber\\
	&= \sum_{l = k}^{k+N-1} \lambda_T ||e_T(l+1)||_2^2 + (1-\lambda_T) ||e_\Psi(l+1)||_2^2 + \lambda_u ||\Delta \b{u}(l)||_1,
\end{align}
where $e_T(k) = T^*(k)-T(k)$ and $e_\Psi(k) = (\Psi_s^*(k))^2-(\Psi_s(k))^2$.
We can now formulate the FCS-MPC problem,
\begin{align}\label{eq:5}
	\b{U}^\opt(k) = \ &\argmin_{\b{U}(k)} \sum_{l = k}^{k+N-1} \lambda_T ||e_T(l+1)||_2^2 + (1-\lambda_T) ||e_\Psi(l+1)||_2^2 + \lambda_u ||\Delta \b{u}(l)||_1 \\
	&\begin{array}{llr}
		\mathrm{s.t.} & \b{x}(l+1) = \b{A}\b{x}(l) + \b{B}\b{u}(l) \\
		& T(l) =\Tfac\b{\psi}_r\times\b{\psi}_s \\
		& \Psi(l) = || \b{\psi}_s(l) ||_2 \\
		& \b{u}(l) \in \{-1,\ 0,\ 1\}^{3} \\
		& l\in\{k, \ldots,\ k + N_\p - 1\},
	\end{array} \nonumber
\end{align}
where $\Delta \b{u}(k) = \b{u}(k) - \b{u}(k-1)$ represents a switch transition, $\b{U}(k) = [\b{u}^\top(k),\ \b{u}^\top(k+1),\cdots,\ \b{u}^\top(k+N-1)]^\top$, and $\b{U}^\opt(k)$ is the optimal input of the optimization problem.

The problem stated above is non-convex due to the non-linear torque term. Additionally, the integer constraints make the problem grow exponentially in complexity with respect to the prediction horizon $N$. An algorithm to solve such problems is discussed next.



\subsection{Solving with branch-and-bound algorithms}\label{sec:4}
We want to solve the optimization problem \eqref{eq:5}. The number of possible input combinations can be represented by the set $\mathcal{U}_N = \{-1,\ 0,\ 1\}^{3N}$, which has a size of $\mathrm{card}(\mathcal{U}_N) = 27^N$. We introduce a branch-and-bound algorithm to solve this optimization problem.

Branch-and-bound is a recursive algorithm that traverses a search tree of all possible input combinations of $\mathcal{U}_N$. Every recursive function call represents a new parent node of the search tree. A parent node has 27 child nodes, representing all possible combinations $\mathcal{U}_1$ that the algorithm can take within one time step, given that all previous inputs are fixed. Each parent node is on a level $l \in \{k,\ k+1,\cdots,\ k+N-1\}$. It represents the time step of the horizon that the input of the node is chosen for.

ADD REPRESENTATIVE SEARCH GRAPH HERE ???

The branch-and-bound algorithm reqires an initial solution $\b{U}_\ini(k)$. We will use the educated guess \cite{tinus_2020}, which uses a shifted version of the previous solution,
\begin{equation}\label{eq:6}
	\b{U}_\ed(k) = \left[\begin{array}{ccccc}
		\0 & \I & \cdots & \cdots & \0 \\
		\0 & \0 & \I & \cdots & \0 \\
		\vdots & & \ddots & \ddots & \vdots \\
		\0 & \cdots & \cdots & \0 & \I \\
		\0 & \cdots & \cdots & \0 & \I
	\end{array}\right] \b{U}(k-1).
\end{equation}
Before starting the branch-and-bound algorithm we compute the initial cost $J_\ini(k) = J_N(\b{U}_\ini(k))$ via \eqref{eq:2}, where $\b{U}_\ini(k) = \b{U}_\ed(k)$.
The advantages and drawbacks of using an educated guess as an initial solution are investigated in Section \ref{sec:1}. Additionally, the feasibility of using an SDP guess similar to the babai estimate of \cite{babai_1986} will be discussed. 

The branch-and-bound algorithm works as follows. When choosing an input in a parent node at level $l$, the cost is computed accordingly. We exploit that the cost in \eqref{eq:2} is additive in the time steps of the prediction horizon. Thus, we can obtain a lower bound by adding up the cost at each step until $l$. In the parent node all possible input combinations $\b{u}(l)\in\mathcal{U}_1$ are traversed. We compute the cost according to each of the inputs. If the cost is lower than the initial cost $J_\ini$, the algorithm jumps into the next parent node. This procedure is repeated until either all child nodes of a parent node are cut, due to too high costs, or a leave node of the search tree is reached. In the case of a leave node, the initial cost is updated to the new cost, and the initial solution to the new solution. 

When a parent node is fully traversed, the branch-and-bound algorithm starts to back propagate. In back propagation the algorithm jumps into the previous parent node. Here, it continues with traversing further child nodes. In this case it can traverse into another branch again or terminate the node and continue the back propagation. Once the back propagation reaches the last child node of the root node, the branch-and-bound algorithm terminates. The solution after termination is guaranteed to be optimal.

The advantage of a branch-and-bound algorithm is that it always prunes a whole sub tree, when cutting a child node that corresponds to a suboptimal solution. Especially in steady-state, a wrong input decision can incur a high cost from early on. In this case large sub-trees are not considered in the algorithm anymore. This speeds up the process of finding a solution to a reasonable speed, such that solutions of even long horizons can be found in real-time. Unfortunately, the performance of this procedure deteriorates when the cost is very high, for instance during transients. In this case sub-optimal decisions are not cut early, as the initial cost is still higher than the cost incurred by a bad input. In the conventional branch-and-bound algorithm the future cost is not considered. This means that at node level $l<k+N-1$, the cost of all future nodes at $l+1,\ l+1, \cdots,\ k+N-1$ is lower bounded by 0. This bound is not tight and leaves the possibility for improvements. For instance, \cite{NL-SDA} shows how the exploitation of lower bounds can lead to speed-ups of up to 20 times in a branch-and-bound algorithm. %Possibilities to cope with this disadvantage will be discussed later on.
%Thus, during transients, we can expect an increasing computational complexity for finding an optimal solution, as many parent nodes have to be traversed.

A formal algorithm for a multi-step controller is given in Algorithm \ref{alg:0} and a conventional branch-and-bound algorithm is shown in Algorithm \ref{alg:1}.

\begin{algorithm}[h!]
	\caption{Multi-Step Controller}
	\label{alg:0}
	\begin{algorithmic}[1]
		\State \textbf{Function:} controller\_nstep
		\State \textbf{Input:} state $\b{x}(k)$, previous input $\b{u}(k-1)$, reference $\b{x}^*(k)$, initial input $\b{U}^\ini(k)$, initial cost $J^\ini(k)$
		\State \textbf{Output:} $\b{u}^\opt(k)$, $\b{U}^\ed(k+1)$ \[\]
		%
%		\State $U^\ini \gets U^\ed(k)$
%		\State $J^\ini \gets J_N(\b{U}_\ini(k))$ 
		\State $\b{U}^\opt(k),\ n_\p \gets$ branch\_and\_bound(0, $J^\ini$, 0, $N$, $\b{0}$, $U^\ini$, $\b{x}(k)$, $\b{u}(k-1)$, $\b{x}^*(k)$, 0)
		\State Compute $U^\ed(k+1)$ according to \eqref{eq:6}.
		\State $\b{u}^\opt(k) \gets \b{U}^\opt_{1:3}(k)$
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
	\caption{Conventional branch-and-bound algorithm}
	\label{alg:1}
	\begin{algorithmic}[1]
		\State \textbf{Function:} branch\_and\_bound
		\State \textbf{Input:} cost so far $J$, current optimal cost estimate $J^\opt$, search tree level $l$, horizon length $N$, input so far $\b{U}$, current optimal input estimate $\b{U}^\opt$, state $\b{x}(k)$, previous input $\b{u}(k-1)$, reference $\b{x}^*(k)$, number of parent nodes traversed so far $n_\p$
		\State \textbf{Output:} $\b{U}^\opt(k)$, $n_\p$ \[\]
		%
		\If{$n_\p \geq n_{\p,\max}$}
			\State return
		\Else
			\State $n_\p = n_\p + 1$
		\EndIf \[\]
		%
		\State $\b{\psi}_\r(k+1) \gets \b{A}_{2,1}\b{\psi}_\s(k) + \b{A}_{2,2}\b{\psi}_\r(k)$
		\ForAll{$\b{u}\in\mathcal{U}_1$}
			\State $\b{\psi}_\s(k+1) \gets \b{A}_{1,1}\b{\psi}_\s(k) + \b{A}_{1,2}\b{\psi}_\r(k) + \b{B}_1\b{u}$
			\State $T(k+1) \gets \Tfac \b{\psi}_\r(k+1)\times\b{\psi}_\s(k+1)$
			\State $\Psi_s(k+1) \gets || \b{\psi}_\s(k+1) ||_2$
			\State $J^\prime \gets J + \lambda_T || T^*(k+1) - T(k+1) ||_2^2 + (1-\lambda_T) || \Psi_s^*(k+1)^2 - \Psi_s(k+1)^2 ||_2^2 + \lambda_\U ||\b{u} - \b{u}(k-1) ||_1$
			\If{$J^\prime < J^\opt$}
				\If{$l < N-1$}
					\State $\b{U}_{3l+1:3(l+1)} \gets \b{u}$
					\State $\b{U}^\opt(k),\ n_\p \gets$ branch\_and\_bound($J^\prime$, $J^\opt$, l+1, $N$, $\b{U}$, $\b{U}^\opt$, $\b{x}(k+1)$, $\b{u}$, $\b{x}^*(k)$, $n_\p$)
				\Else
					\State $\b{U}_{3l+1:3(l+1)} \gets \b{u}$
					\State $\b{U}^\opt \gets \b{U}$
					\State $J^\opt \gets J^\prime$
				\EndIf
			\EndIf
		\EndFor
	\end{algorithmic}
\end{algorithm}



%\section{SDP relaxations}
%
%\subsection{Problem definition}
%
%\subsection{Solvers}


