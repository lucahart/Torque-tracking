\documentclass[a4paper,11pt,twoside]{book}

% Language setting
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with`a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=black]{hyperref}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{gensymb}
\usepackage{bbm}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tikz,pgfplots}
\usepackage{graphicx}
\usepackage{siunitx}
\usetikzlibrary{positioning}
\usetikzlibrary{calc}
\usepackage{booktabs}
\usepackage{xcolor,calc}
\usetikzlibrary{arrows}
\usetikzlibrary{shapes.geometric}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
% \usepackage[framed,numbered,autolinebreaks,useliterate]{mcode}

\newcommand{\dc}{\mathrm{dc}}
\newcommand{\abc}{\mathrm{abc}}
\newcommand{\A}{\mathrm{a}}
\newcommand{\B}{\mathrm{b}}
\newcommand{\C}{\mathrm{c}}
\newcommand{\g}{\mathrm{g}}
\newcommand{\ph}{\mathrm{ph}}
\newcommand{\sw}{\mathrm{sw}}
\newcommand{\s}{\mathrm{s}}
\newcommand{\TDD}{\mathrm{TDD}}
\newcommand{\err}{\mathrm{err}}
\newcommand{\p}{\mathrm{p}}
\newcommand{\U}{\mathrm{u}}
\newcommand{\temp}{\mathrm{temp}}
\newcommand{\PI}{\mathrm{PI}}
\newcommand{\unc}{\mathrm{unc}}
\newcommand{\ctrl}{\mathrm{ctrl}}
\newcommand{\kI}{k_\mathrm{I}}
\newcommand{\kP}{k_\mathrm{P}}
\newcommand{\mavg}{\mathrm{mavg}}
\newcommand{\Sim}{\mathrm{sim}}
\renewcommand{\b}[1]{\boldsymbol{#1}}
\newlength{\fheight}
\newlength{\fwidth}
\newcommand{\I}{\b{I}}
\newcommand{\0}{\b{0}}
\newcommand{\bab}{\mathrm{bab}}
\newcommand{\ed}{\mathrm{ed}}
\newcommand{\ini}{\mathrm{ini}}
\newcommand{\augp}{\mathrm{aug}}
\newcommand{\augs}{\mathrm{aug}}
\newcommand{\opt}{\mathrm{opt}}
\newcommand{\Tfac}{T_\mathrm{factor}}
\renewcommand{\sp}{\text{ }}
\DeclareSIUnit{\pu}{pu}
\DeclareSIUnit{\rpm}{rpm}
\newcommand{\Opt}{Opt }
\newcommand{\Ed}{Ed guess }
\newcommand{\Edsdp}{Ed \& sdp guess }
\newcommand{\Edplus}{Ed guess + sdp }

\DeclareMathOperator*{\argmin}{\mathrm{argmin}}
\definecolor{blueCol}{rgb}{0, 0.447 0.741}

\begin{document}

\chapter{Numerical Case Studies}

\section{Performance metrics}\label{sec:2}
The goal of this work is to show the applicability of FCS-MPC for torque control in a real world setting. Performance metrics give us an understanding about the tracking and time performance that the proposed algorithms have. The proposed FCS-MPC tracks the torque and absolute stator flux. The tracking performance can be quantified by the root-mean squared (rms) error. That is
\begin{equation*}
	e_T(k) = ||T^*(k) - T(k)||_2^2
\end{equation*}
for the torque $T(k)$ and 
\begin{equation*}
	e_\Psi(k) = ||\Psi^*(k) - \Psi(k)||_2^2
\end{equation*}
for the absolute stator flux $\Psi(k)$, where $T^*(k)$ and $\Psi^*(k)$ are the torque and absolute stator flux reference, respectively.
In addition we measure the cost accumulated by the controller. It is defined as
\begin{equation*}
	J_{acc}(k) = \sum_{l = 0}^{k} J(k).
\end{equation*}
The accumulated cost is a simple way of comparing different controller performances. It will later be used to show how different controllers perform in certain operational points, such as steps.

Besides the tracking performance of the controllers, the computational time plays a major role. It can vary strongly depending on the operational conditions of the controller and is a major challenge in non-convex torque tracking. Yet, measuring the solving time in a simulation can be a challenge; unlike an embedded device, a computer can be affected by a variety of working conditions that influence the solving time. To better estimate the time on an embedded device, the number of function calls of the recursive branch-and-bound algorithm will be taken into consideration. A function call can be interpreted as a parent node in the search tree of the branch-and-bound algorithm. Therefore, in the remainder, we will refer to the number of parent nodes $n_p$ visited to resemble the computational time. For the simulation discussed in Section \ref{sec:1}, we observed a correlation of $\mathrm{Corr}(t,n_p) = 0.9989$ between the computational time $t$ and the number of parent nodes $n_p$.

The quality of the initial guess of the branch-and-bound algorithm can be measured by the number of iterations performed. An iterations refers to an update of the current optimal solution, when a leaf node of the search tree is reached. Thus, 0 iterations mean that the initial guess was optimal, $n$ iterations mean the branch-and-bound algorithm updated the initial solution $n$ times to obtain the optimal solution.


\section{Parameter Choices and Simulation Setting}
There are view hyper parameters that have to be chosen for the controller. The cost function contains the torque weighting factor $\lambda_T$, which discounts the torque ripple to prioritize the flux magnitude ripple, without changing the cost ratio between these two terms and the switching penalty. % Maybe put this sentence to the introduction of the cost function ...
We use the same parameter choice $\lambda_T = 0.052$. In addition we have to decide about the switching penalty $\lambda_u$. It is chosen to $\lambda_u = 1.8\times10^{-3}$ to achieve a switching frequency of approximately $f_\sw = \SI{250}{\hertz}$. The sampling intervals of all controllers are chosen to $T_\s = \SI{100}{\micro\second}$ and the horizons are $N = 5$. 
Additionally, in the case of a parent node limit we use $n_{p,max} = 250$, unless stated otherwise. Table \ref{tab:2} contains a list of all controller parameters.
\begin{table}[h!]
	\centering
	\begin{tabular}{ccc}
		\toprule
		parameter name & parameter symbol & parameter values \\
		\midrule[\heavyrulewidth]
		torque weighting factor & $\lambda_T$ & $0.052$ \\
		switching weight & $\lambda_\U$ & $1.8\times10^{-3}$\\
		sampling interval & $T_\s$ & $\SI{100}{\micro\second}$\\
		horizon & $N$ & $5$\\
		upper parent node bound & $n_{p,max}$ & $250$\\
		\bottomrule
	\end{tabular}
	\caption{Controller parameters.}
	\label{tab:2}
\end{table}

Our comparisons are based on a simulation of a scenario with a ramp-up, step-down, and step-up of the torque. The absolute stator flux reference will be kept at a constant level $\Psi^* = 1$. Figure \ref{fig:9} shows the torque reference.
\begin{figure}[h!]
	\centering
	\includegraphics[width=.7\textwidth]{Images/Fig9}
	\caption{Torque reference.}
	\label{fig:9}
\end{figure}

The simulation and FCS-MPC run at different speeds. Throughout all scenarios a simulation sampling interval of $T_\Sim = \SI{0.5}{\micro\second}$ is used. The
rotor has a fundamental frequency of $f_1 = \SI{1494}{\rpm} = \SI{24.9}{\hertz}$. The rotor and stator flux measurements are perturbed by $\eta \sim \mathcal{U}(-2.5 \times 10^{-3},\ 2.5 \times 10^{-3})$, where $\mathcal{U}(a,\ b)$ is the uniform distribution in the interval $[a,\ b]$. All simulation parameters can be found in Table \ref{tab:3} and all machine parameters are stated in \ref{tab:4}.
\begin{table}[h!]
	\centering
	\begin{tabular}{ccc}
		\toprule
		parameter name & parameter symbol & parameter values \\
		\midrule[\heavyrulewidth]
		Simulation sampling interval & $T_\Sim$ & $\SI{.5}{\micro\second}$ \\
		\bottomrule
	\end{tabular}
	\caption{Simulation parameters.}
	\label{tab:3}
\end{table}
\begin{table}[h!]
	\centering
	\begin{tabular}{cc}
		\toprule
		parameter name & parameter value \\
		\midrule[\heavyrulewidth]
		Voltage & $\SI{3300}{\volt}$ \\
		Current & $\SI{356}{\ampere}$ \\
		Real power & $\SI{1.587}{\mega\watt}$ \\
		Apparent power & $\SI{2.035}{\mega\volt\ampere}$ \\
		Stator frequency & $\SI{50}{\hertz}$ \\
		Rotational speed & $\SI{1494}{\rpm}$ \\
		\midrule
		Stator resistance & $R_s = \SI{.0108}{\pu}$ \\
		Rotor resistance & $R_r = \SI{.0091}{\pu}$ \\
		Stator leak. react. & $X_{ls} = \SI{.1493}{\pu}$ \\
		Rotor leak. react. & $X_{lr} = \SI{.1104}{\pu}$ \\
		Main reactance & $X_m = \SI{2.349}{\pu}$ \\
		Total leak. react. & $X_\sigma = \SI{.2548}{\pu}$ \\
		\midrule
		dc-link voltage & $V_{dc} = \SI{1.930}{\pu}$ \\
		dc-link capacitance &  $X_c \SI{11.769}{\pu}$ \\
		\bottomrule
	\end{tabular}
	\caption{Machine parameters.}
	\label{tab:4}
\end{table}


\section{Advantages of Multi-Step control}



\section{Computational feasibility}

\subsection{Drawbacks of Conventional Branch-and-Bound Algorithms}\label{sec:1}
Being non-convex, torque tracking imposes a major challenge on the FCS-MPC formulation. The non-convexity does not allow us to use the sphere decoder discussed in \cite{dorf_2019}. When deciding upon an input, the sphere decoder has an intuition about the possible future cost (REFERENCE NEEDED HERE?). As a result, it is very fast in pruning sub-trees that do not belong to the optimal solution. In \cite{NL-SDA} the weakness of conventional branch-and-bound algorithms can be seen. We can achieve a major decrease in computational time, when a more meaning full lower bound is introduced. It helps the decoder to estimate the minimum accumulated cost in the future when applying a certain input. In the discussed case a speed-up of more than three times on average and up to twenty times in single cases was achieved.

In \cite{NL-SDA} a non-linear function for upper-bounding the converter's switching frequency was discussed. The major advantage was the existence of a simple lower bound on the switching frequency; if there is no switching applied. In the case of torque tracking such a lower bound does not exist. Possibilities for estimating future branch costs via SDP relaxations for torque tracking will be further discussed in Section \ref{sec:0}.
\begin{figure}[h!]
	\centering
	\includegraphics[width=.7\textwidth]{Images/Fig0}
	\caption{Number of traversed parent nodes $n_p$.}
	\label{fig:0}
\end{figure}

Figure \ref{fig:0} depicts the number of traversed nodes for a simulation with a conventional branch-and-bound algorithm. The educated guess is used as an initial solution and there is no limit on the number of parent nodes that are traversed. The torque reference is shown in black to give an intuition about the operational condition that the branch-and-bound algorithm is in at each time step. We can observe a high peak during the torque step-up. In this case the number of traversed parent nodes reaches up to $n_p = 4297$. When excluding all time steps with $n_p \geq 250$ we can calculate an average of $\bar{n}_p \approx 18.5$ with a standard deviation of $\mathrm{std}(n_p) \approx 15.5$. This simulation shows the central problem of the convectional branch-and-bound algorithm: The number of parent nodes traversed tends to explode in some cases.

In \cite{gey_book} and \cite{dorf_2019} different methods for initializing the sphere decoder were discussed. To obtain an intuition about the relevance of a good initial guess for the used branch-and-bound algorithm we will compare three different initial solutions.
\begin{enumerate}
	\item \textit{Bad guess} is a vector of zeros. It represents a bad initial solution.
	\item \textit{Ed guess} is the educated guess.
	\item \textit{Opt guess} is the optimal solution computed by the previous algorithm. It serves as a benchmark for how good an initial solution can at most be.
\end{enumerate}
\begin{figure}[h!]
	\centering
	\includegraphics[width=.7\textwidth]{Images/Fig1}
	\caption{Number of traversed parent nodes $n_p$. Comparison of branch-and-bound algorithms without node limits, but different initial guesses.}
	\label{fig:1}
\end{figure}
\begin{table}[h!]
	\centering
	\begin{tabular}{cccc}
		\toprule
		Initial solution & mean & std & max \\
		\midrule[\heavyrulewidth]
		Bad guess & $218.4$ & $149.2$ & $6948$ \\
		Ed guess & $19.4$ & $18.2$ & $4318$ \\
		Opt guess & $16.6$ & $11.8$ & $914$ \\
		\bottomrule
	\end{tabular}
	\caption{Simulated number of nodes traversed for different initial guesses. \textit{mean} and \textit{std} refer to the mean and standard deviation of all measurements with less than 250 traversed parent nodes (approximatelly steady-state). All measurements are in number of parent nodes traversed.}
	\label{tab:0}
\end{table}
%FIG1: number of Parent nodes traversed, 
%TAB0: mean and std outside of step-operation. Removed all samples with more than 250 visited parent nodes (maybe find a better metric?) ...
%Additionally, max nodes observed
%bad guess: mean=201.0, std=93.0, max=52,163
%ed guess:  mean=30.6, std=28.7, max=35,194
%opt guess: mean=24.7, std=18.7, max=19,422

Figure \ref{fig:1} shows the number of parent nodes traversed for each initial guess. The bad guess continuously traverses the highest number of parent nodes. Note that during steady-state the ed guess and opt guess always stay below 250 parent nodes with a mean of 30.6 and 24.7 parent nodes, respectively (see Table \ref{tab:0}). %Table \ref{tab:0} shows the mean and standard deviation for all initial guesses outside of step-operation.
This shows that having a good initial guess is important during steady-state to keep the solving time small. The ed guess is a good enough estimate, as the number of nodes is still far below our maximum bound of 250 nodes.

In contrast, we observe a high peak in the number of nodes during the torque step-up. The measured number of visited parent nodes increase up to $6948$, $4318$, and $914$, respectively. All of these values are too high to be computed in real time on an embedded device. The reason for these high numbers during step-up compared to ramps and step-downs is the value of the cost function. The \textit{No node limit} benchmark in Figure \ref{fig:3} shows that the torque takes longer to follow the reference during step-up compared to step-down or continuous reference tracking. The bad tracking leads to much higher values of the cost function. The bad intuition of the branch-and-bound algorithm about future nodes makes it traverse many nodes on non-optimal paths before pruning the respective sub-trees.
\begin{figure}[h!]
	\centering
	\includegraphics[width=.7\textwidth]{Images/Fig3}
	\caption{Torque of systems controlled by controllers with an educated guess as initial solution. \textit{No node limit} has no node limit and \textit{Ed guess} has a node limit of 250 nodes.}
	\label{fig:3}
\end{figure}

We will now investigate the influence of an upper bound of 250 parent nodes. Therefore, we initialize with an educated guess and execute two branch-and-bound algorithms. The first execution is done without a node limit to give an optimal benchmark. The second execution is done with a node limit of 250 parent nodes. Figure \ref{fig:3} shows the torque tracking of the two controllers. We can observe that both controllers behave very similarly until the torque step-up. During the step-up the controller with an upper node limit performs much worse than the benchmark. This shows that cutting the branch-and-bound algorithm due to time constraints can lead to suboptimality and deteriorate the controller's performance.

We can conclude that branch-and-bound algorithms are well suited for FCS-MPC with torque tracking during most operational modes, such as ramps, steady-state, and step-downs. Some operational conditions, such as torque step-ups lead to a great number of parent nodes that have to be traversed. They make branch-and-bound algorithms badly suited for solving the FCS-MPC's optimization problem. This raises the question on how to solve for good-enough solutions in real time during these operational modes.


\subsection{Applicability of different speed-ups}\label{sec:0}
To speed-up the solving during step-ups we will discuss different possibilities of utilizing SDP relaxations.
First, we can improve the branch-and-bound algorithm by giving an estimate of the future cost in a branch. Here, SDP relaxations can be used to get an estimate of optimal switch transitions. Then we can round the solution and compute the respective cost. During simulations we have observed that getting a realistic guess takes at least 250 gradient descent iterations, when using the first-order scs solver \ref{scs}. Lets assume that an SDP would be executed only in the root-note. In the worst case it will be used 27 times, which would lead to 6750 gradient descent iterations in addition to the normal branch-and-bound execution. We do not expect a good-enough trade off between the resulting reduction of visited parent nodes and executed gradient descent iterations to solve the branch-and-bound algorithm in real time.

Alternatively, the SDP relaxation can be used to compute one guess per controller sample. Directly applying the SDP guess does not lead to a good average performance compared to the educated guess with a branch-and-bound algorithm (see Table \ref{tab:1}). Nevertheless, the SDP relaxation has a constant solving time in every operational mode, when fixing the number of gradient descent iterations. Therefore, it is able to compute a good-enough solution, when the branch-and-bound algorithm fails due to its varying solving time. We thought of the following two algorithms that apply an SDP guess.
\begin{enumerate}
	\item \textit{\Ed} is a branch-and-bound algorithm that starts with an educated guess, with an upper limit of 250 parent nodes.
	\item \textit{\Edsdp} is a branch-and-bound algorithm with an upper limit of 250 parent nodes. But it starts with the best of the educated guess and the SDP guess.
	\item \textit{\Edplus} is a branch-and-bound algorithm that uses an educated guess, with an upper limit of 250 parent nodes. Additionally, an SDP guess is computed in parallel. In the final step, the best of the two is chosen.
\end{enumerate}
Both algorithms can potentially be executed in real time. Solving the SDP relaxation takes longer than obtaining the educated guess. It is difficult to estimate the number of parent nodes that corresponds to the additional computational complexity of the SDP guess. This makes a comparison of \Ed and \Edsdp difficult. Thus, we use \Edplus to benchmark improvements compared to \Ed. Computing the SDP guess in parallel to branch-and-bound does not influence the number of traversed parent nodes in the branch-and-bound algorithm and therefore, eases the comparison.

Note that \Edsdp has an at least as good solution as \Edplus, as the branch-and-bound algorithm can at most improve a solution. Thus, \Edsdp gives a lower bound for the performance of both algorithms.

%There exist various possibilities to extract a 1-dimensional solution from the SDP matrix $\b{X}$. The computational time also depends on this estimate. Table \ref{tab:1} compares the average cost of the different guesses. We can observe that ... -> rounding first column is good enough!
%
%TAB1: average costs of SDP guesses are compared with the average educated guess

\subsection{Performance of algorithms}
We will now apply the above mentioned alternative to solve an SDP relaxation once a controller sample. The comparison is done between the following three methods:
\begin{enumerate}
	\item \textit{\Opt} is a branch-and-bound algorithm that starts with an educated guess. It does not have an upper node limit and serves as an optimal benchmark.
	\item \textit{\Ed} is a branch-and-bound algorithm that starts with an educated guess, with an upper limit of 250 parent nodes.
	\item \textit{\Edsdp} is a branch-and-bound algorithm with an upper limit of 250 parent nodes. But it starts with the best of the educated guess and the SDP guess.
%	\item \textit{\Edplus} is a branch-and-bound algorithm that uses an educated guess, with an upper limit of 250 parent nodes. Additionally, an SDP guess is computed in parallel. In the final step, the best of the two is chosen.
\end{enumerate}
Figure \ref{fig:3} showed a comparison of \Opt and \Ed already. Figure \ref{fig:4} additionally contains the torques that are observed for \Edsdp and \Edplus. All controllers behave very similarly until the step-up. At the step-up \Ed performs badly, while \Edsdp and \Edplus are following the reference as good as the benchmark \Opt. This behavior can also be seen in the accumulated cost depicted in Figure \ref{fig:5}. It shows how the cost of \Ed accumulated much more than the other algorithms during the step-up. Figure \ref{fig:6} shows the number of nodes that are visited by the different algorithms. We can observe the high number of parent nodes that \Opt traverses, while all other algorithms are cut at 250 parent nodes. This shows that the SDP approximation is able to achieve a close-to-optimal performance when the branch-and-bound algorithm is not able to. 
\begin{figure}[h!]
	\centering
	\includegraphics[width=.7\textwidth]{Images/Fig4}
	\caption{Torque of systems with the controllers stated above.}
	\label{fig:4}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=.7\textwidth]{Images/Fig5}
	\caption{Accumulated costs of the controllers stated above.}
	\label{fig:5}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=.7\textwidth]{Images/Fig6}
	\caption{Number of traversed parent nodes $n_p$. Comparison of branch-and-bound algorithms with different node limits and different initial guesses.}
	\label{fig:6}
\end{figure}

Methods \Edsdp and \Edplus give very good results. \Edsdp is slightly better, because the branch-and-bound algorithm can exploit the knowledge of the SDP guess. Nevertheless, \Edplus could be more realistic, since it is easier that the branch-and-bound algorithm and the SDP are computed parallely. Nevertheless, solving the SDP relaxation would take some time in \Edsdp before branch-and-bound starts. It is difficult to estimate the number of parent nodes that corresponds to the additional computational complexity of the SDP guess. Thus, we recommend using \Edplus, as the SDP guess is just computed in parallel to branch-and-bound. This could provide enough time to solve the SDP relaxation and does not influence the number of traversed parent nodes in the branch-and-bound algorithm. (THIS BELONGS IN THE PREVIOUS CHAPTER. CHECK IF THERE IS A POSSIBILITY TO JUST LEAVE OUT THE NEXT TWO FIGURES.)
%\begin{figure}[h!]
%	\centering
%	\includegraphics[width=.7\textwidth]{Images/Fig4}
%	\caption{Torque of systems with different controllers. Node limits modified to $n_{p,max} = 500$ parent nodes, if existent.}
%	\label{fig:7}
%\end{figure}
%\begin{figure}[h!]
%	\centering
%	\includegraphics[width=.7\textwidth]{Images/Fig5}
%	\caption{Accumulated costs of different controllers. Node limits modified to $n_{p,max} = 500$ parent nodes, if existent.}
%	\label{fig:8}
%\end{figure}

Figures \ref{fig:4} to \ref{fig:6} were all computed for 250 gradient descent iterations to solve the SDP relaxation. To compare this performance to a possible optimum, we ran the same simulation with an upper limit of 500 gradient descent iterations. The resulting torques and accumulated costs are depicted in Figure \ref{fig:7} and \ref{fig:8}, respectively. Here, we cannot observe a difference between the torques of \Opt, \Edsdp, and \Edplus. The same holds for the accumulated cost. This leads to the conclusion that already applying as many iterations in the SDP solver leads to close-to-optimal performance. Given we can execute more gradient descent iterations, \Edsdp and \Edplus approach \Opt even closer.





\bibliographystyle{ieeetr}
\bibliography{bibliography}



\end{document}